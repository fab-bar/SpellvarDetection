#!/usr/bin/env python

## Script to create training pairs for a type-based filter
## reads
## - a dictionary containing types and corresponding spellvars (spellvardict)
## - a dictionary containing types and spellvar candidates created by some generator (canddict)
## - a list with tokens used to get the frequency of the types (token_file)
## - a frequency threshold to exclude infrequent types from the negative pairs (type_freq)
## and outputs positive and negative pairs in separate files
## resampling allows to balance the number of pairs by subsampling the majority class

import argparse
import json
import random
import collections

from spellvardetection.util.learn_simplification_rules import getPairsFromSpellvardict

parser = argparse.ArgumentParser()
parser.add_argument('spellvardict')
parser.add_argument('canddict')
parser.add_argument('token_file')
parser.add_argument('type_freq', type=int)
parser.add_argument('outfile_positive')
parser.add_argument('outfile_negative')
parser.add_argument('--resample', action='store_true')
args = parser.parse_args()

tokens = json.load(open(args.token_file, 'r'))
typecounts = collections.Counter([token['type'] for token in tokens])

pos_pairs = set([])
neg_pairs = set([])

spellvarpairs = getPairsFromSpellvardict(json.load(open(args.spellvardict, 'r')))
candidatepairs = getPairsFromSpellvardict(json.load(open(args.canddict, 'r')))

for pair in candidatepairs:
    if pair in spellvarpairs:
        pos_pairs.add(pair)
    else:
        neg_pairs.add(pair)

neg_pairs = set([neg_pair for neg_pair in neg_pairs if typecounts[neg_pair[0]] >= args.type_freq and typecounts[neg_pair[1]] >= args.type_freq])

if args.resample:
    if len(neg_pairs) > len(pos_pairs):
        neg_pairs = random.sample(neg_pairs, len(pos_pairs))
    elif len(pos_pairs) > len(neg_pairs):
        pos_pairs = random.sample(pos_pairs, len(neg_pairs))

json.dump(list(pos_pairs), open(args.outfile_positive, 'w'))
json.dump(list(neg_pairs), open(args.outfile_negative, 'w'))
